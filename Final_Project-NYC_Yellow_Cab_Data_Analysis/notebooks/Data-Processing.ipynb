{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from shapely.geometry import shape, Point\n",
    "import csv\n",
    "from csv import DictWriter as DictWriter\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import glob\n",
    "import requests\n",
    "import requests.auth\n",
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim()\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "longWeekends = {'2016-01':{'2016-01-01'}}\n",
    "\n",
    "print(longWeekends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fileNames = glob.glob('..\\\\Taxi\\\\*.csv')\n",
    "for fileName in fileNames:\n",
    "    print(\"Reading file: {0}\".format(fileName))\n",
    "    extracted_month = fileName.replace('..\\\\Taxi\\\\yellow_tripdata_','').replace('.csv','')\n",
    "    if extracted_month in longWeekends:\n",
    "        #Get the long weekend dates\n",
    "        longWeekendDates = longWeekends.get(extracted_month)\n",
    "        #Read the csv for the month\n",
    "        df = pd.read_csv(fileName)\n",
    "        #Extract and add the travel date in the dataframe\n",
    "        print(\"Adding travel date in the dataframe\")\n",
    "        df['travel_date'] = df['tpep_pickup_datetime'].apply(lambda x: datetime.strptime(x , '%Y-%m-%d %H:%M:%S').date())\n",
    "        print(\"Creating file structure\")\n",
    "        for i in df.VendorID.unique():\n",
    "            print(\"Filtering Vendor: {0}\".format(i))\n",
    "            dfi = df[df['VendorID'] == i]\n",
    "            #print(dfi.head())\n",
    "            for dt in dfi.travel_date.unique():\n",
    "                print(\"Filtering Date: {0}\".format(dt))\n",
    "                if str(dt) in longWeekendDates:\n",
    "                    dfidt = dfi[dfi['travel_date'] == dt]\n",
    "\n",
    "                    #Create folder\n",
    "                    data_file_folder = 'Data/'+str(i)+'/'+extracted_month\n",
    "                    if not os.path.exists(data_file_folder):\n",
    "                        os.makedirs(data_file_folder)\n",
    "                    #file format Data/VendorId/Month/Day.csv\n",
    "                    data_file_name = data_file_folder+'/'+str(dt)+'.csv'\n",
    "                    print(\"CSV created: {0}\".format(data_file_name))\n",
    "                    dfidt.to_csv(data_file_name, sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extracted_files = glob.glob('..\\\\Data\\\\*\\\\*\\\\original\\\\*.csv')\n",
    "for fileName in extracted_files:\n",
    "    #Read the file\n",
    "    print(\"Reading file: {0}\".format(fileName))\n",
    "    df = pd.read_csv(fileName,chunksize= 500)\n",
    "    i = 0\n",
    "    #split the filename\n",
    "    path_list = fileName.split('\\\\')\n",
    "    #update the parent folder name\n",
    "    path_list[-2] = 'processed' \n",
    "    folder_path = '\\\\'.join(path_list[:-1])\n",
    "    savefile_name = path_list[-1]\n",
    "    savefile_name = savefile_name.replace('.csv','')\n",
    "    for chunk in df:\n",
    "        chunk.to_csv(folder_path+'\\\\'+savefile_name+'_'+str(i)+'.csv', index=True, index_label='index')\n",
    "        i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Load geoJson\n",
    "with open('..\\\\Resources\\\\nyboroughs.geojson') as f:\n",
    "    js = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getLocation(long, lat):\n",
    "    point = Point(long,lat)\n",
    "    area = \"Not Specified\"\n",
    "    # check each polygon to see if it contains the point\n",
    "    for feature in js['features']:\n",
    "        polygon = shape(feature['geometry'])\n",
    "        if polygon.contains(point):\n",
    "            area = feature['properties']['name']\n",
    "            break\n",
    "    return area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: Data/1/2016-01/processed\\2016-01-01_279.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_279.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_28.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_28.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_280.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_280.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_281.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_281.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_282.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_282.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_283.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_283.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_284.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_284.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_285.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_285.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_286.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_286.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_287.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_287.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_288.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_288.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_289.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_289.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_29.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_29.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_290.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_290.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_291.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_291.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_292.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_292.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_293.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_293.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_294.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_294.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_295.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_295.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_296.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_296.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_297.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_297.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_298.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_298.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_299.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_299.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_3.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_3.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_30.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_30.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_300.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_300.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_301.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_301.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_31.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_31.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_32.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_32.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_33.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_33.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_34.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_34.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_35.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_35.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_36.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_36.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_37.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_37.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_38.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_38.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_39.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_39.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_4.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_4.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_40.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_40.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_41.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_41.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_42.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_42.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_43.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_43.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_44.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_44.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_45.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_45.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_46.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_46.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_47.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_47.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_48.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_48.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_49.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_49.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_5.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_5.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_50.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_50.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_51.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_51.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_52.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_52.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_53.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_53.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_54.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_54.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_55.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_55.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_56.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_56.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_57.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_57.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_58.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_58.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_59.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_59.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_6.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_6.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_60.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_60.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_61.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_61.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_62.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_62.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_63.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_63.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_64.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_64.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_65.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_65.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_66.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_66.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_67.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_67.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_68.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_68.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_69.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_69.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_7.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_7.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_70.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_70.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_71.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_71.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_72.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_72.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_73.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_73.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_74.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_74.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_75.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_75.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_76.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_76.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_77.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_77.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_78.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_78.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_79.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_79.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_8.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_8.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_80.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_80.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_81.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_81.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_82.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_82.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_83.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_83.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_84.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_84.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_85.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_85.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_86.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_86.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_87.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_87.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_88.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_88.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_89.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_89.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_9.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_9.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_90.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_90.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_91.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_91.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_92.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_92.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_93.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_93.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_94.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_94.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_95.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_95.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_96.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_96.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_97.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_97.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_98.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_98.csv\n",
      "Reading file: Data/1/2016-01/processed\\2016-01-01_99.csv\n",
      "Saving file: Data/1/2016-01/processed\\2016-01-01_99.csv\n"
     ]
    }
   ],
   "source": [
    "extracted_files = glob.glob('..\\\\Data\\\\*\\\\*\\\\processed\\\\*.csv')\n",
    "location_list = {}\n",
    "for fileName in extracted_files:\n",
    "    #Read the file\n",
    "    print(\"Reading file: {0}\".format(fileName))\n",
    "    df = pd.read_csv(fileName)\n",
    "    for index, row in df.iterrows():\n",
    "        location_list[index] = {'index': row['index'],\n",
    "                                'pickup_area':getLocation(row['pickup_longitude'],row['pickup_latitude']),\n",
    "                                'dropoff_area':getLocation(row['dropoff_longitude'],row['dropoff_latitude'])}\n",
    "    \n",
    "    location_df = pd.DataFrame.from_dict(location_list, orient='index')\n",
    "    new_df = pd.merge(df, location_df, on='index', how='inner', right_index=False, left_index=False)\n",
    "    print(\"Saving file: {0}\".format(fileName))\n",
    "    new_df.to_csv(fileName, sep=',', encoding='utf-8', index=False)\n",
    "    location_list = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "access_token = None\n",
    "CLIENT_ID = 'xLAmv1MmKerS'\n",
    "CLIENT_SECRET = 'VzZHSkFTrZQQFJuGROA3nzqVSJTgbmvW'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrieveAccessToken():\n",
    "    url = \"https://api.lyft.com/oauth/token\"\n",
    "    client_auth = requests.auth.HTTPBasicAuth(CLIENT_ID , CLIENT_SECRET)\n",
    "\n",
    "    hdrs = {'Content-Type': 'application/json', 'grant_type':'client_credentials', 'scope': 'public'}\n",
    "    r = requests.post(url, auth=client_auth,data= hdrs)\n",
    "    if r.status_code == 200:\n",
    "        #Set access token\n",
    "        current_token = r.json()['access_token']\n",
    "        access_token = current_token\n",
    "    else:\n",
    "        print('Error retrieving access token')\n",
    "        sys.exit(0)\n",
    "    return current_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getRideEstimate(row):\n",
    "    \n",
    "    if row['pickup_area'] == \"Not Specified\" or row['dropoff_area'] == \"Not Specified\":\n",
    "        return pd.Series([\"0.0\",\"0.0\",\"0.0\",\"0.0\", \"0\"], index=['lyft_cost','lyft_plus_cost', 'lyft_line_cost', 'lyft_distance', 'lyft_duration'])\n",
    "    \n",
    "    if access_token is not None:\n",
    "        current_token = access_token\n",
    "    else:\n",
    "        current_token = retrieveAccessToken()\n",
    "    \n",
    "    ride_estimate_url = \"https://api.lyft.com/v1/cost\"\n",
    "    \n",
    "    payload = {'start_lat':row['pickup_latitude'], 'start_lng': row['pickup_longitude'],\n",
    "               'end_lat': row['dropoff_latitude'], 'end_lng': row['dropoff_longitude']}\n",
    "\n",
    "    hdrs = {'Authorization': 'bearer '+ current_token}\n",
    "    time.sleep(0.004)\n",
    "    ride_estimate = requests.get(ride_estimate_url, params=payload, headers = hdrs)\n",
    "    estimates = ride_estimate.json()['cost_estimates']\n",
    "    dict = {}\n",
    "    for i in range(0,len(estimates)):\n",
    "        dict[estimates[i]['ride_type']+'_cost'] = estimateCalculation(estimates[i])\n",
    "    \n",
    "    dict['lyft_distance'] = estimates[0]['estimated_distance_miles']\n",
    "    dict['lyft_duration'] = estimates[0]['estimated_duration_seconds']\n",
    "    \n",
    "    estimate_series = pd.Series(data=dict, index=['lyft_cost','lyft_plus_cost', 'lyft_line_cost', 'lyft_distance', 'lyft_duration'])\n",
    "    return estimate_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def estimateCalculation(estimate):\n",
    "    \n",
    "    estimated_cost = (estimate['estimated_cost_cents_max']+ estimate['estimated_cost_cents_min'])/200\n",
    "    if not estimate['primetime_percentage'] == 0:\n",
    "        primetime_percentage = int(estimate['primetime_percentage'].replace('%',''))\n",
    "        \n",
    "        estimated_cost = (estimated_cost/(100+primetime_percentage))*100\n",
    "        \n",
    "    return format(float(estimated_cost), '.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extracted_files = glob.glob('..\\\\Data\\\\*\\\\*\\\\processed\\\\*.csv')\n",
    "for fileName in extracted_files:\n",
    "    print(\"Reading file: {0}\".format(fileName))\n",
    "    df = pd.read_csv(fileName)\n",
    "    data = df.apply(lambda row: getRideEstimate(row), axis=1)\n",
    "    data.columns = ['lyft_cost','lyft_plus_cost', 'lyft_line_cost', 'lyft_distance', 'lyft_duration']\n",
    "    df = df.join(data)\n",
    "    \n",
    "    #split the filename\n",
    "    path_list = fileName.split('\\\\')\n",
    "    #update the parent folder name\n",
    "    path_list[-2] = 'lyftdata' \n",
    "    full_path = '\\\\'.join(path_list)\n",
    "    #Save the file\n",
    "    df.to_csv(full_path, sep=',', encoding='utf-8', index=False)\n",
    "    print(\"CSV update: {0}\".format(full_path))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
